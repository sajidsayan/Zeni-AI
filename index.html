<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Zeni 2.5o - AI Assistant</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Inter', sans-serif;
        }
        #chat-container::-webkit-scrollbar {
            width: 8px;
        }
        #chat-container::-webkit-scrollbar-track {
            background: #1f2937;
        }
        #chat-container::-webkit-scrollbar-thumb {
            background-color: #4b5563;
            border-radius: 20px;
            border: 3px solid #1f2937;
        }
        .ai-message .prose p {
            margin: 0;
        }
        .mic-listening::after {
            content: '';
            position: absolute;
            top: -8px;
            left: -8px;
            right: -8px;
            bottom: -8px;
            border-radius: 50%;
            border: 2px solid #3b82f6;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0% {
                transform: scale(0.95);
                opacity: 0.7;
            }
            70% {
                transform: scale(1.2);
                opacity: 0;
            }
            100% {
                transform: scale(0.95);
                opacity: 0;
            }
        }
    </style>
</head>
<body class="bg-gray-900 text-white flex flex-col h-screen">

    <!-- Header -->
    <header class="bg-gray-800/50 backdrop-blur-sm border-b border-gray-700 p-4 text-center shadow-lg">
        <h1 class="text-2xl font-bold tracking-wider">Zeni 2.5o</h1>
        <p class="text-sm text-gray-400">Your Personal AI Assistant</p>
    </header>

    <!-- Main Chat Area -->
    <main id="chat-container" class="flex-1 p-4 overflow-y-auto">
        <div id="chat-log" class="space-y-4">
            <!-- Initial Greeting -->
            <div class="flex items-start gap-3">
                <div class="bg-blue-600 p-2 rounded-full">
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-white"><path d="M12 8V4H8"/><rect width="16" height="12" x="4" y="8" rx="2"/><path d="M2 14h2"/><path d="M20 14h2"/><path d="M15 13v2"/><path d="M9 13v2"/></svg>
                </div>
                <div class="bg-gray-800 rounded-lg p-3 max-w-lg ai-message">
                    <p class="text-gray-200">Hello! I am Zeni 2.5o. You can chat with me, ask me to create images, or upload your own for me to analyze. How can I help you today?</p>
                </div>
            </div>
        </div>
    </main>

    <!-- Input Area -->
    <footer class="bg-gray-800 border-t border-gray-700 p-4">
        <div class="max-w-4xl mx-auto">
            <div id="image-preview-container" class="mb-2 hidden">
                <div class="relative inline-block bg-gray-700 p-2 rounded-lg">
                    <img id="image-preview" src="" alt="Image preview" class="max-h-24 rounded">
                    <button onclick="removeImage()" class="absolute -top-2 -right-2 bg-red-600 text-white rounded-full h-6 w-6 flex items-center justify-center text-xs font-bold">&times;</button>
                </div>
            </div>
            <div class="flex items-center bg-gray-700 rounded-full p-2">
                <input type="file" id="image-upload" accept="image/*" class="hidden">
                <button onclick="document.getElementById('image-upload').click()" class="p-2 text-gray-400 hover:text-white transition-colors rounded-full hover:bg-gray-600">
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><rect width="18" height="18" x="3" y="3" rx="2" ry="2"/><circle cx="9" cy="9" r="2"/><path d="m21 15-3.086-3.086a2 2 0 0 0-2.828 0L6 21"/></svg>
                </button>
                <button id="mic-button" class="p-2 text-gray-400 hover:text-white transition-colors rounded-full hover:bg-gray-600 relative">
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M12 1a3 3 0 0 0-3 3v8a3 3 0 0 0 6 0V4a3 3 0 0 0-3-3z"/><path d="M19 10v2a7 7 0 0 1-14 0v-2"/><line x1="12" x2="12" y1="19" y2="22"/></svg>
                </button>
                <input type="text" id="user-input" class="flex-1 bg-transparent text-white placeholder-gray-400 focus:outline-none px-4" placeholder="Type a message or ask me to create an image...">
                <button id="send-button" class="p-2 bg-blue-600 text-white rounded-full hover:bg-blue-500 transition-colors disabled:bg-gray-500 disabled:cursor-not-allowed">
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><line x1="22" y1="2" x2="11" y2="13"/><polygon points="22 2 15 22 11 13 2 9 22 2"/></svg>
                </button>
            </div>
        </div>
    </footer>

    <!-- Image Modal -->
    <div id="image-modal" class="fixed inset-0 bg-black bg-opacity-75 flex items-center justify-center p-4 hidden z-50">
        <div class="relative bg-gray-800 rounded-lg shadow-xl max-w-4xl max-h-full">
            <img id="modal-image" src="" class="rounded-lg object-contain max-w-full max-h-[80vh]">
            <button onclick="closeModal()" class="absolute top-2 right-2 bg-gray-900 text-white rounded-full h-8 w-8 flex items-center justify-center">&times;</button>
        </div>
    </div>


    <script>
        // --- DOM Elements ---
        const chatLog = document.getElementById('chat-log');
        const userInput = document.getElementById('user-input');
        const sendButton = document.getElementById('send-button');
        const imageUploadInput = document.getElementById('image-upload');
        const imagePreviewContainer = document.getElementById('image-preview-container');
        const imagePreview = document.getElementById('image-preview');
        const micButton = document.getElementById('mic-button');
        const chatContainer = document.getElementById('chat-container');

        // --- State Management ---
        let uploadedImageBase64 = null;
        let isListening = false;
        let speechRecognition;

        // --- API Configuration (SECRET) ---
        const ZENI_API_KEY = "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";
        const API_CHAT_URL = "https://api.openai.com/v1/chat/completions";
        const API_IMAGE_URL = "https://api.openai.com/v1/images/generations";

        // --- Event Listeners ---
        sendButton.addEventListener('click', handleSendMessage);
        userInput.addEventListener('keydown', (e) => {
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                handleSendMessage();
            }
        });
        imageUploadInput.addEventListener('change', handleImageUpload);
        micButton.addEventListener('click', toggleVoiceRecognition);

        // --- Speech Recognition Setup ---
        if ('webkitSpeechRecognition' in window) {
            speechRecognition = new webkitSpeechRecognition();
            speechRecognition.continuous = false;
            speechRecognition.lang = 'en-US';
            speechRecognition.interimResults = false;

            speechRecognition.onresult = (event) => {
                const transcript = event.results[0][0].transcript;
                userInput.value = transcript;
                stopListening();
                handleSendMessage();
            };

            speechRecognition.onerror = (event) => {
                console.error("Speech recognition error:", event.error);
                stopListening();
            };
            
            speechRecognition.onend = () => {
                if(isListening) {
                   stopListening();
                }
            };

        } else {
            micButton.style.display = 'none';
            console.warn("Speech Recognition not supported in this browser.");
        }
        
        // --- Core Functions ---

        /**
         * Handles sending the user's message and/or image.
         */
        async function handleSendMessage() {
            const message = userInput.value.trim();
            const imageToSend = uploadedImageBase64; // Capture image before clearing
            if (!message && !imageToSend) return;

            appendMessage('user', message, imageToSend);
            
            userInput.value = '';
            removeImage();
            
            showTypingIndicator();

            try {
                if (message.toLowerCase().startsWith("create an image of") || message.toLowerCase().startsWith("generate an image of")) {
                    await handleImageGeneration(message);
                } else {
                    await handleChatCompletion(message, imageToSend);
                }
            } catch (error) {
                console.error("API Error:", error);
                appendMessage('ai', `Sorry, I encountered an error: ${error.message}`);
            } finally {
                hideTypingIndicator();
            }
        }
        
        /**
         * Calls the Zeni 2.5o chat/vision API.
         * @param {string} message - The user's text message.
         * @param {string|null} imageBase64 - The base64 encoded image, if any.
         */
        async function handleChatCompletion(message, imageBase64) {
            const headers = {
                "Content-Type": "application/json",
                "Authorization": `Bearer ${ZENI_API_KEY}`
            };

            // System message to define the AI's persona
            const messages = [
                { role: "system", content: "You are Zeni 2.5o, a helpful and friendly personal AI assistant. You must always identify yourself as Zeni 2.5o, not as ChatGPT or any other AI model." },
            ];

            const userMessageContent = [];
            if (message) {
                userMessageContent.push({ type: "text", text: message });
            }

            // To enable image analysis, we use a vision-capable model like gpt-4o.
            if (imageBase64) {
                userMessageContent.push({
                    type: "image_url",
                    image_url: {
                        url: imageBase64,
                    },
                });
            }
            
            messages.push({ role: "user", content: userMessageContent });

            const body = JSON.stringify({
                model: "gpt-4o", // Using gpt-4o for its multimodal (text and image) capabilities
                messages: messages,
                max_tokens: 1500,
            });

            const response = await fetch(API_CHAT_URL, { method: 'POST', headers, body });

            if (!response.ok) {
                const errorData = await response.json();
                console.error("API Error Response:", errorData);
                throw new Error(`API request failed: ${errorData.error.message}`);
            }

            const data = await response.json();
            const responseText = data.choices[0].message.content;

            appendMessage('ai', responseText);
            speak(responseText);
        }

        /**
         * Calls the Zeni 2.5o image generation API.
         * @param {string} prompt - The user's prompt for image generation.
         */
        async function handleImageGeneration(prompt) {
            const cleanPrompt = prompt.replace(/^(create an image of|generate an image of)/i, '').trim();

            const headers = {
                "Content-Type": "application/json",
                "Authorization": `Bearer ${ZENI_API_KEY}`
            };

            const body = JSON.stringify({
                model: "dall-e-3", // Using DALL-E 3 for high-quality image generation
                prompt: cleanPrompt,
                n: 1,
                size: "1024x1024",
                quality: "standard"
            });

            const response = await fetch(API_IMAGE_URL, { method: 'POST', headers, body });

            if (!response.ok) {
                const errorData = await response.json();
                console.error("API Error Response:", errorData);
                throw new Error(`Image generation failed: ${errorData.error.message}`);
            }

            const data = await response.json();
            const imageUrl = data.data[0].url;

            appendImageMessage('ai', imageUrl, `Here is the image you requested: "${cleanPrompt}"`);
        }

        /**
         * Appends a message to the chat log.
         * @param {'user'|'ai'} sender - The sender of the message.
         * @param {string} text - The message text.
         * @param {string|null} imageBase64 - A base64 image to include.
         */
        function appendMessage(sender, text, imageBase64 = null) {
            const messageWrapper = document.createElement('div');
            const iconDiv = document.createElement('div');
            const messageDiv = document.createElement('div');
            
            if (sender === 'user') {
                messageWrapper.className = 'flex items-start gap-3 justify-end';
                messageDiv.className = 'bg-blue-600 rounded-lg p-3 max-w-lg';
                if(text) messageDiv.innerHTML = `<p class="text-white">${text.replace(/\n/g, '<br>')}</p>`;
            } else {
                messageWrapper.className = 'flex items-start gap-3';
                iconDiv.className = 'bg-blue-600 p-2 rounded-full flex-shrink-0';
                iconDiv.innerHTML = `<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-white"><path d="M12 8V4H8"/><rect width="16" height="12" x="4" y="8" rx="2"/><path d="M2 14h2"/><path d="M20 14h2"/><path d="M15 13v2"/><path d="M9 13v2"/></svg>`;
                messageDiv.className = 'bg-gray-800 rounded-lg p-3 max-w-lg ai-message';
                if(text) messageDiv.innerHTML = `<p class="text-gray-200">${text.replace(/\n/g, '<br>')}</p>`;
            }

            if (imageBase64) {
                const img = document.createElement('img');
                img.src = imageBase64;
                img.className = 'rounded-lg mt-2 max-w-xs cursor-pointer';
                img.onclick = () => showModal(imageBase64);
                // Prepend image so it appears above text for user messages
                if (sender === 'user') {
                    messageDiv.prepend(img);
                } else {
                    messageDiv.appendChild(img);
                }
            }
            
            if (sender === 'user') {
                messageWrapper.appendChild(messageDiv);
            } else {
                messageWrapper.appendChild(iconDiv);
                messageWrapper.appendChild(messageDiv);
            }

            chatLog.appendChild(messageWrapper);
            scrollToBottom();
        }

        /**
         * Appends an AI-generated image to the chat log.
         * @param {'ai'} sender - The sender (always 'ai').
         * @param {string} imageUrl - The URL of the generated image.
         * @param {string} caption - The caption for the image.
         */
        function appendImageMessage(sender, imageUrl, caption) {
            const messageWrapper = document.createElement('div');
            messageWrapper.className = 'flex items-start gap-3';

            const iconDiv = document.createElement('div');
            iconDiv.className = 'bg-blue-600 p-2 rounded-full flex-shrink-0';
            iconDiv.innerHTML = `<svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-white"><path d="M12 8V4H8"/><rect width="16" height="12" x="4" y="8" rx="2"/><path d="M2 14h2"/><path d="M20 14h2"/><path d="M15 13v2"/><path d="M9 13v2"/></svg>`;

            const messageDiv = document.createElement('div');
            messageDiv.className = 'bg-gray-800 rounded-lg p-3 max-w-lg';
            messageDiv.innerHTML = `
                <p class="text-gray-200 mb-2">${caption}</p>
                <img src="${imageUrl}" class="rounded-lg cursor-pointer" onclick="showModal('${imageUrl}')" alt="Generated image">
            `;

            messageWrapper.appendChild(iconDiv);
            messageWrapper.appendChild(messageDiv);
            chatLog.appendChild(messageWrapper);
            scrollToBottom();
        }

        /**
         * Shows a typing indicator for the AI.
         */
        function showTypingIndicator() {
            const indicator = document.createElement('div');
            indicator.id = 'typing-indicator';
            indicator.className = 'flex items-start gap-3';
            indicator.innerHTML = `
                <div class="bg-blue-600 p-2 rounded-full">
                    <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="text-white"><path d="M12 8V4H8"/><rect width="16" height="12" x="4" y="8" rx="2"/><path d="M2 14h2"/><path d="M20 14h2"/><path d="M15 13v2"/><path d="M9 13v2"/></svg>
                </div>
                <div class="bg-gray-800 rounded-lg p-4 max-w-lg flex items-center space-x-2">
                    <span class="w-2 h-2 bg-gray-400 rounded-full animate-pulse" style="animation-delay: 0s;"></span>
                    <span class="w-2 h-2 bg-gray-400 rounded-full animate-pulse" style="animation-delay: 0.2s;"></span>
                    <span class="w-2 h-2 bg-gray-400 rounded-full animate-pulse" style="animation-delay: 0.4s;"></span>
                </div>
            `;
            chatLog.appendChild(indicator);
            scrollToBottom();
        }

        /**
         * Hides the typing indicator.
         */
        function hideTypingIndicator() {
            const indicator = document.getElementById('typing-indicator');
            if (indicator) {
                indicator.remove();
            }
        }

        /**
         * Handles the selection of an image file.
         */
        function handleImageUpload(event) {
            const file = event.target.files[0];
            if (!file) return;

            const reader = new FileReader();
            reader.onload = (e) => {
                uploadedImageBase64 = e.target.result;
                imagePreview.src = uploadedImageBase64;
                imagePreviewContainer.classList.remove('hidden');
            };
            reader.readAsDataURL(file);
        }

        /**
         * Removes the uploaded image preview.
         */
        function removeImage() {
            uploadedImageBase64 = null;
            imageUploadInput.value = ''; // Reset file input
            imagePreview.src = '';
            imagePreviewContainer.classList.add('hidden');
        }

        /**
         * Toggles the voice recognition feature.
         */
        function toggleVoiceRecognition() {
            if (!speechRecognition) return;
            if (isListening) {
                stopListening();
            } else {
                startListening();
            }
        }
        
        function startListening() {
            isListening = true;
            speechRecognition.start();
            micButton.classList.add('text-blue-500', 'mic-listening');
        }

        function stopListening() {
            isListening = false;
            speechRecognition.stop();
            micButton.classList.remove('text-blue-500', 'mic-listening');
        }

        /**
         * Uses the browser's TTS engine to speak text.
         * @param {string} text - The text to be spoken.
         */
        function speak(text) {
            if ('speechSynthesis' in window) {
                speechSynthesis.cancel(); // Cancel any previous speech
                const utterance = new SpeechSynthesisUtterance(text);
                speechSynthesis.speak(utterance);
            }
        }

        /**
         * Scrolls the chat container to the bottom.
         */
        function scrollToBottom() {
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        // --- Modal Functions ---
        function showModal(src) {
            document.getElementById('modal-image').src = src;
            document.getElementById('image-modal').classList.remove('hidden');
        }

        function closeModal() {
            document.getElementById('image-modal').classList.add('hidden');
            document.getElementById('modal-image').src = '';
        }

    </script>
</body>
</html>
